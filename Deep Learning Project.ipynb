{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Luyakana Jordan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "BASE_TEST_DIR = '../input/birdsong-recognition' if os.path.exists('../input/birdsong-recognition/test_audio') else '../input/my-birdcall-datasets'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cette Première cellule nous permet de spécifier le Chemin du répertoire où l'on a mis nos datasets . \n",
    "Si le dossier test_audio existe on ne rajoute rien sinon on rajoute my_-bircall-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2, librosa, random, torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On importe toutes les bibliothèques qu' on aura besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hparams():\n",
    "    def __init__(self):\n",
    "        #resnet50 resnext50_32x4d mobilenet_v2 efficientnet-b3  densenet121 densenet169 \n",
    "        self.models_name = ['resnet50','efficientnet-b0','efficientnet-b0','efficientnet-b0','efficientnet-b0','resnet50']\n",
    "        self.chk = ['resnet50_78_0.830_0.666.pt','enet0_101_0.771_0.692.pt','enet0_45_0.558.pt','enet0_133_0.707_0.691.pt',\n",
    "                    '150enet0_116_0.707_0.703.pt','2.5resnet50_113_0.715_0.693.pt']\n",
    "        self.count_bird = [265,265,265,265,150,265] #count birds|Количество птиц, 264 - all, 265 + nocall\n",
    "        self.len_chack = [448,448,448,448,448,224] # The duration of the training files 448 = 5 second|Длительность обучающих файлов\n",
    "        \n",
    "        self.mel_folder = './mel/'\n",
    "        self.n_fft = 892\n",
    "        self.sr = 21952 \n",
    "        self.hop_length=245\n",
    "        self.n_mels =  224\n",
    "        self.win_length = self.n_fft\n",
    "        self.batch_size = 100 # 3 - b7, 8 - b5,  12 - b3, 25 - b0, 18 - b1 70\n",
    "        self.lr = 0.001\n",
    "        self.border = 0.5\n",
    "        self.save_interval = 200 #Model saving interval\n",
    "        \n",
    "        # Список из count_bird птиц по пополуярности\n",
    "        self.bird_count = pd.read_csv('../input/my-birdcall-datasets/bird_count.csv').ebird_code.to_numpy()        \n",
    "        self.BIRD_CODE = {b:i for i,b in enumerate(self.bird_count)}\n",
    "        self.INV_BIRD_CODE = {v: k for k, v in self.BIRD_CODE.items()}\n",
    "        self.bird_count = self.bird_count[:self.count_bird[0]]\n",
    "\n",
    "\n",
    "hp = Hparams()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dans la cellule suivante nous allons détailler la classe Hparams ainsi que ses méthodes , dans un premier temps on lui donne des paramètres qui vont nous permettre d'initialiser un ensemble de valeurs qui nous permettront de faire appel à différentes méthodes . \n",
    "\n",
    "1) models_name : C'est la liste de tous les models que l'on va utiliser durant le Notebook , en faisant des recherches il a choisi des modèles qui ont  \n",
    "2) chk : c'est la liste des autres models sauvegardés dans des fichiers \n",
    "3) count_bird : Le nombre d'oiseaux \n",
    "4) len_chack : Le temps qu'on a utilisé pour les audios . \n",
    "5) mel_folder : Correspond au dossier où l'on mettre nos melspectogrammes \n",
    "6) n_fft : longueur de la fenêtre FFT\n",
    "7) sr : taux de l'echantillonage \n",
    "8) hop_length : nombre d'échantillons entre les trames successives\n",
    "9) n_mels : \n",
    "10) win_length : \n",
    "11) batch_size : la taille \n",
    "12) lr : le learning rate \n",
    "13) border : le seuil \n",
    "14) save_interval : le nombre de sauvegarde \n",
    "15) bird_count : Fichier csv qui contient les codes des oiseaux avec les codes de pays\n",
    "16) Bird_Code : récupére tous les codes des oiseaux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X: np.ndarray,len_chack, mean=0.5, std=0.5, eps=1e-6):\n",
    "    trans = transforms.Compose([transforms.ToPILImage(),\n",
    "                                        transforms.Resize([hp.n_mels, len_chack]), transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "    V = (255 * X).astype(np.uint8)\n",
    "    V = (trans(V)+1)/2\n",
    "    return V"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "La méthode mono_to_color : Cette méthode permet de normaliser nos images , la variable trans contient l' appel de la méthode transforms.Compose qui permet lier plusieurs transfomatiosn à la fois , la première transformation qu'on va appliquer c'est pour avoir une Pili image , ensuite on va redimensionner la taille de l'image , ensuite on va créer un tenseur en faisant une mise à l'echelle en changeant la plage qui passera à 0-1 , On va ensuite normaliser notre tenseur avce la moyenne et l'ecart type . \n",
    "On sait que la méthode mono_color contient un tableau n-dimensionnel , on concatène les dimensions pour en avoir une seule puis on normalise en multipliant par 255 et pour terminer on apllique la transformation . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "    return f1_score(y_true > hp.border, y_pred > hp.border, average=\"samples\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--> La accuracy : La méthode accuracy nous permet de calculer le score F1 , elle prend nos vraies labels et nos labels predits pour les comparer avec le border qui est le seuil . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectr(train_path):\n",
    "    # Load file | Загружаем файл\n",
    "    y, _ = librosa.load(train_path,sr=hp.sr,mono=True,res_type=\"kaiser_fast\")\n",
    "\n",
    "    # Create melspectrogram | Создать Мелспектрограмму\n",
    "    spectr = librosa.feature.melspectrogram(y, sr=hp.sr, n_mels=hp.n_mels, n_fft=hp.n_fft, hop_length = hp.hop_length, win_length = hp.win_length, fmin = 300)\n",
    "    return spectr.astype(np.float16)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--> La méthode get_melspectr : Cette méthode nous permet de récupérer transformer notre audio sous la forme du melspectogramme ( on l'expliquera dans notre petit guide) , la bibliothèque librosa nous permet de charger des audios et de faire certaines transformations . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_power(images, power = 1.5, c= 0.7):\n",
    "    images = images - images.min()\n",
    "    images = images/(images.max()+0.0000001)\n",
    "    images = images**(random.random()*power + c)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--> random_power : Cette methode permet de jouer sur le contraste de l'image en enlevant les pixels les plus faibles et en augmentant les pixels les plus fort . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(preds, log_stat= False, border=0.5):\n",
    "    answer = pd.read_csv('../input/my-birdcall-datasets/example_test_audio_summary.csv')\n",
    "    preds = answer.merge(preds, how = 'right', left_on='filename_seconds', right_on='row_id')\n",
    "    y_true, y_pred = [], []\n",
    "    my_bird = 0\n",
    "    pred_bird = 0\n",
    "    bad_bird = {}    \n",
    "    for all in preds.loc[:,['bird','birds']].to_numpy(): \n",
    "        y = np.zeros(265)\n",
    "        c = np.array(all[0].split())\n",
    "        for bird in c:\n",
    "            y[hp.BIRD_CODE[bird]]=1\n",
    "        y_true.append(y)\n",
    "        \n",
    "        y = np.zeros(265)\n",
    "        d = np.array(all[1].split())\n",
    "        for bird in d:\n",
    "            y[hp.BIRD_CODE[bird]]=1\n",
    "        y_pred.append(y)\n",
    "        \n",
    "        mask = np.in1d(d, c)\n",
    "        #good += mask.sum()\n",
    "        if d[0] != 'nocall':\n",
    "            pred_bird += len(d)\n",
    "        if mask.sum()>0 and d[0] != 'nocall':\n",
    "            my_bird += mask.sum()\n",
    "        for i in d[~mask]:\n",
    "            if i in bad_bird:\n",
    "                bad_bird[i] += 1\n",
    "            else:\n",
    "                bad_bird[i] = 1\n",
    "        #all_bird += (len(c)+len(d))/2\n",
    "    if not pred_bird: pred_bird = 1\n",
    "    f1 = f1_score(y_true, y_pred, average=\"samples\")\n",
    "    print(\"border: %.1f bird: %d bird_accuracy: %.3f test_accuracy: %.3f\" % (\n",
    "                                border,my_bird, my_bird/pred_bird, f1)) \n",
    "    if log_stat:\n",
    "        for w in sorted(bad_bird, key=bad_bird.get, reverse=True)[:5]:\n",
    "            print (w, bad_bird[w])            \n",
    "    \n",
    "    return my_bird, my_bird/pred_bird, f1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--> Test_accuracy : Cette methode permet à partir de nos valeurs prédites de calculer l'accuracy , le score F1 et de renvoyer le nombre d'oiseaux . \n",
    "On va récupérer des données à partir du CSV et on va les merger avec les preds . On va boucler sur nos valeurs de nos \"birds\" et on va récupérer nos vrais labels et nos labels prédits , on va ensuite comparer les choses qu'on a dans le tabeau c et d grace a np.in1d qui va nous renvoyer un tableau rempli de \"False\" et de \"True\" . \n",
    "A partir de nos valeurs remplies on va appeler pouvoir calculer l'accuracy et le score f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdcallNet(nn.Module):\n",
    "    def __init__(self, name, num_classes=265):\n",
    "        super(BirdcallNet, self).__init__()\n",
    "        self.model = models.__getattribute__(name)(pretrained=False)\n",
    "        if name in [\"resnet50\",\"resnext50_32x4d\"]:\n",
    "            self.model.fc = nn.Linear(2048, num_classes)\n",
    "        elif name in ['resnet18','resnet34']:\n",
    "            self.model.fc = nn.Linear(512, num_classes)\n",
    "        elif  name ==\"densenet121\":\n",
    "            self.model.classifier = nn.Linear(1024, num_classes)\n",
    "        elif name in ['alexnet','vgg16']:\n",
    "            self.model.classifier[-1] = nn.Linear(4096, num_classes)\n",
    "        elif name ==\"mobilenet_v2\":\n",
    "            self.model.classifier[1] = nn.Linear(1280, num_classes)\n",
    "        #print(self.model)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dans cette cellule on définit notre Réseau , on définit une transformation linéaire avec des tailles différentes en entrée mais la taille de sortie est la meme pour tous nos reseaux on a 265 sorties qui correspondent aux 265 classes d'oiseaux . \n",
    "\n",
    "On définit notre méthode forward pour effectuer une propagation vers l'avant , on va juste appeler le model qu'on aura selectionné . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name,chk,count_bird):\n",
    "    best_bird_count,best_score, epochs = 0,0,1\n",
    "    all_loss, train_accuracy = [], []\n",
    "    f1_scores,t_scores,b_scores = [],[],[]\n",
    "    if not chk and model_name in ['efficientnet-b3','efficientnet-b0']:\n",
    "        model = EfficientNet.from_pretrained(model_name, num_classes = count_bird).cuda()\n",
    "        optimizer = Adam(model.parameters(), lr = hp.lr)\n",
    "    else:\n",
    "        models_names = ['alexnet','resnet50','resnet18','resnet34','mobilenet_v2','densenet121','resnext50_32x4d','densenet169']\n",
    "        if model_name in models_names:\n",
    "            model = BirdcallNet(model_name, hp.count_bird[0]).cuda()\n",
    "        elif model_name == 'mini':\n",
    "            model = Classifier(hp.count_bird[0]).cuda()\n",
    "        else:\n",
    "            model = EfficientNet.from_name(model_name, override_params={'num_classes': count_bird }).cuda()\n",
    "        optimizer = Adam(model.parameters(), lr = hp.lr)\n",
    "        # Load a checkpoint | Загрузить чекпоинт\n",
    "        if chk:\n",
    "            ckpt = torch.load('../input/my-birdcall-datasets/'+chk)\n",
    "            model.load_state_dict(ckpt['model'])\n",
    "            epochs = int(ckpt['epoch']) + 1\n",
    "            train_accuracy =  ckpt['train_accuracy'] \n",
    "            all_loss   = ckpt['all_loss'] \n",
    "            best_bird_count =  ckpt['best_bird_count'] \n",
    "            best_score   = ckpt['best_score']\n",
    "            \n",
    "            if 'optimizer' in ckpt:\n",
    "                optimizer.load_state_dict(ckpt['optimizer'])\n",
    "            if 't_scores' in ckpt:\n",
    "                t_scores   = ckpt['t_scores']\n",
    "            if 'f1_scores' in ckpt:\n",
    "                f1_scores   = ckpt['f1_scores']\n",
    "            if 'b_scores' in ckpt:\n",
    "                b_scores   = ckpt['b_scores']\n",
    "            print('Чекпоинт загружен: Эпоха %d Число обнаруженых птиц %d Score %.3f' % (epochs,best_bird_count,best_score))\n",
    "    return model,optimizer, epochs, train_accuracy, all_loss, best_bird_count, best_score, t_scores, f1_scores, b_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "La méthode get_model va nous permettre de selectionner le model que nous souhaitons :\n",
    "\n",
    "--> Dand un premier temps : si la variable chk n'est pas présente et que la variable model_name est présente dans la liste ['efficientnet-b3','efficientnet-b0'] : on choisit un model Efficient qui est déjà pré-entrainé et on applique l'optimiseur Adam ( méthode de descente de gradient stochastique ) avec un learning rate défini plus haut à 0.001 . \n",
    "\n",
    "-- > Dans un second temps : On definit une autre liste puis on regarde si le model_name fait parti de cette liste ['alexnet','resnet50','resnet18','resnet34','mobilenet_v2','densenet121','resnext50_32x4d','densenet169'] si c'est le cas on appelle le réseau qu'on crée plus haut , si le nom est egal à 'mini' on appelle un Classifier avec les 255 classes et sinon on appelle le model EfficientNet mais dans ce cas il ne sera pas pré-entrainé puis on applique l'optimiseur Adam . \n",
    "\n",
    "--> Et si chk contient quelque chose alors on charge l'objet avec torch.load , la variable ckpt va contenir un dictionnaire du model et de ses parametres , la méthode load_state_dict va charger le dictionnaire de paramètre du modèle , on va récuperer le nombre d'epochs grace à la variable \"epochs\" , et ça va etre le meme procédé pour le train accuracy , le all_loss , le best_bird_count , l'optimizer , t_scores , f1_scores et b_scores . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "import glob, os,time, random, librosa, argparse\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "#from hparams import Hparams, get_model, mono_to_color,random_power, accuracy, get_melspectr, test_accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from tqdm import tqdm\n",
    "from scipy.stats.mstats import gmean\n",
    "        \n",
    "def preprocess():\n",
    "    os.makedirs(hp.mel_folder, exist_ok=True)\n",
    "    dataset = glob.glob(os.path.join(\"./short/\", '**/*.wav'), recursive=True)\n",
    "    with open('meta.csv', 'w', encoding=\"utf-8\") as output:\n",
    "        output.write(\"file,bird\\n\")\n",
    "        for train_path in tqdm(dataset):\n",
    "            # Only the name of the file | Только название файла\n",
    "            wav_name = os.path.basename(train_path) \n",
    "            dirname = train_path.split(\"\\\\\")[1]\n",
    "            \n",
    "            # Create melspectrogram | Получить спектр\n",
    "            mel = get_melspectr(train_path)\n",
    "            \n",
    "            # Translate to torch | Перевести в torch\n",
    "            mel = torch.from_numpy(mel)\n",
    "            \n",
    "            # Getting a new path to the file | Получаем новый путь до файла\n",
    "            wav_path = os.path.join(hp.mel_folder, wav_name)\n",
    "\n",
    "            # Save melspectrogram | Сохраняем иелспектрограмму\n",
    "            save_path = wav_path.replace('.mp3', '.amp')\n",
    "            torch.save(mel, save_path)\n",
    "            output.write(wav_name +',' + dirname + \"\\n\")\n",
    "    secondary_labels = pd.read_csv('train1.csv')\n",
    "    meta = pd.read_csv('meta.csv')\n",
    "    meta = meta.merge(secondary_labels[[\"filename\",'labels_bg']], how = 'left', left_on='file', right_on='filename',copy=False)\n",
    "    meta[[\"file\",\"bird\",'labels_bg']].to_csv('meta.csv', index=False)\n",
    "    print('Training dataset created / Тренировочный датасет создан')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--> Cette méthode va nous permettre de transformer tous nos audios en melspectogrammes et de les sauvegarder directement sur son ordinateur , son pc étant assez faible il était obliger de passer par cette solutipn pour travailler avec tous les fichiers . \n",
    "\n",
    "On commence par récupérer le nom du fichier en splittant avec (\\\\) , on va ensuite créer un melespectogramme avec la méthode crée plus haut (get_melespectr) . \n",
    "Grace à la methode torch.numpy on va pouvoir créer un tenseur à partir du mel (numpy) , on crée un nouveau chemin pour le fichier et on va le sauvegarder et on termine par créer notre training dataset . \n",
    "\n",
    "Cette étape est importante pour pouvoir travailler sur nos audios, l'étape de transformation en melspectogramme va nous servir à récuperer beaucoup plus d'informations que si on avait laissé nos audios sous la forme brut . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(Dataset):\n",
    "    def __init__(self, bird_list, hp):\n",
    "        # Initialize the list of melspectrograms | Инициализировать список мелспектрограмм\n",
    "        self.bird_list = bird_list\n",
    "        self.hp = hp\n",
    "        self.noise = pd.read_csv(\"nocall.csv\")\n",
    "        self.stop_border = 0.3 # Probability of stopping mixing | Вероятность прервать смешивание\n",
    "        self.level_noise = 0.05 # level noise | Уровень шума\n",
    "        self.div_coef = 100 # signal amplification during mixing | Усиления сигнала при смешивании\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.bird_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx2 = random.randint(0, len(self.bird_list)-1) # Second file | Второй файл\n",
    "        idx3 = random.randint(0, len(self.bird_list)-1) # Third file | Третий файл\n",
    "\n",
    "        y = torch.zeros(self.hp.count_bird[0])\n",
    "        birds, background = [],[]\n",
    "        \n",
    "        # Length of the segment | Длительность отрезка\n",
    "        self.len_chack = random.randint(self.hp.len_chack[0]-48, self.hp.len_chack[0]+52)\n",
    "        #self.len_chack = self.hp.len_chack[0]\n",
    "        \n",
    "        images = np.zeros((self.hp.n_mels, self.len_chack)).astype(np.float32)            \n",
    "        for i,idy in enumerate([idx,idx2,idx3]):\n",
    "            # Choosing a record with a bird | Выбираем запись с птицей\n",
    "            sample = self.bird_list.loc[idy, :]\n",
    "            # Uploading a record with a bird | Загружаем запись с птицей\n",
    "            mel = torch.load(self.hp.mel_folder+sample.file.replace(\".mp3\",\".amp\")).numpy()\n",
    "\n",
    "            # Birds in the file | Птицы в файле\n",
    "            labels_bird = sample.bird.split()\n",
    "            for bird in labels_bird:\n",
    "                if not bird in birds and bird != 264:\n",
    "                    birds.append(self.hp.BIRD_CODE[bird])\n",
    "            \n",
    "            # Birds in the background | Птицы на фоне     \n",
    "            if sample.labels_bg:\n",
    "                labels_bg = sample.labels_bg.split()\n",
    "                for bg in labels_bg:\n",
    "                    if not bg in background:\n",
    "                        background.append(self.hp.BIRD_CODE[bg])\n",
    "            \n",
    "            # Select the piece that contains the sound | Выбираем кусок в котором содержится звук\n",
    "            if mel.shape[1]>self.len_chack: \n",
    "                start = random.randint(0, mel.shape[1] - self.len_chack - 1)\n",
    "                mel = mel[:, start : start + random.randint(self.len_chack-48, self.len_chack)]\n",
    "            else:\n",
    "                len_zero = random.randint(0, self.len_chack-mel.shape[1])\n",
    "                mel = np.concatenate((np.zeros((self.hp.n_mels,len_zero)),mel), axis=1)\n",
    "            \n",
    "            mel = np.concatenate((mel,np.zeros((self.hp.n_mels,self.len_chack-mel.shape[1]))), axis=1)\n",
    "            \n",
    "            # Change the contrast | Изменить контрастность\n",
    "            mel = random_power(mel, power = 3, c= 0.5)\n",
    "            #mel = librosa.power_to_db(mel.astype(np.float32), ref=np.max)\n",
    "            #mel = (mel+80)/80\n",
    "            \n",
    "            # Mix the signal | Смешать сигнал\n",
    "            images = images + mel*(random.random() * self.div_coef + 1)\n",
    "            \n",
    "            # Abort accidentally | Случайно прервать \n",
    "            if random.random()<self.stop_border:\n",
    "                break\n",
    "        \n",
    "        # Add a different sound without birds | Добавить другой звук без птиц\n",
    "        idy = random.randint(0, len(self.noise)-1)\n",
    "        sample = self.noise.loc[idy, :]\n",
    "        mel = torch.load('./mel/'+sample.file.replace(\".wav\",\".amp\")).numpy()\n",
    "        mel = np.concatenate((np.zeros((self.hp.n_mels,self.len_chack)),mel), axis=1)\n",
    "        mel = np.concatenate((mel,np.zeros((self.hp.n_mels,self.len_chack))), axis=1)\n",
    "        start = random.randint(0, mel.shape[1] - self.len_chack - 1)\n",
    "        mel = mel[:, start : start + self.len_chack]\n",
    "        mel = random_power(mel)\n",
    "        #mel = librosa.power_to_db(mel.astype(np.float32), ref=np.max)\n",
    "        #mel = (mel+80)/80\n",
    "        images = images + mel/(mel.max()+0.0000001)*(random.random()*1+0.5)*images.max()\n",
    "        \n",
    "        # In db and normalize | В Дб и нормализовать\n",
    "        images = librosa.power_to_db(images.astype(np.float32), ref=np.max)\n",
    "        images = (images+80)/80\n",
    "        \n",
    "        # Add noise | Добавить шум\n",
    "        # Add white noise | Добавить белый шум            \n",
    "        if random.random()<0.9:\n",
    "            images = images + (np.random.sample((self.hp.n_mels,self.len_chack)).astype(np.float32)+9) * images.mean() * self.level_noise * (np.random.sample() + 0.3)\n",
    "        \n",
    "        # Add pink noise | Добавить розовый шум\n",
    "        if random.random()<0.9:\n",
    "            r = random.randint(1,self.hp.n_mels)\n",
    "            pink_noise = np.array([np.concatenate((1 - np.arange(r)/r,np.zeros(self.hp.n_mels-r)))]).T\n",
    "            images = images + (np.random.sample((self.hp.n_mels,self.len_chack)).astype(np.float32)+9) * 2  * images.mean() * self.level_noise * (np.random.sample() + 0.3)\n",
    "        \n",
    "        # Add bandpass noise | Добавить полосовой шум\n",
    "        if random.random()<0.9:\n",
    "            a = random.randint(0, self.hp.n_mels//2)\n",
    "            b = random.randint(a+20, self.hp.n_mels)\n",
    "            images[a:b,:] = images[a:b,:] + (np.random.sample((b-a,self.len_chack)).astype(np.float32)+9) * 0.05 * images.mean() * self.level_noise  * (np.random.sample() + 0.3)\n",
    "        \n",
    "        \n",
    "        # Lower the upper frequencies | Понизить верхние частоты\n",
    "        if random.random()<0.5:\n",
    "            images = images - images.min()\n",
    "            r = random.randint(self.hp.n_mels//2,self.hp.n_mels)\n",
    "            x = random.random()/2\n",
    "            pink_noise = np.array([np.concatenate((1-np.arange(r)*x/r,np.zeros(self.hp.n_mels-r)-x+1))]).T\n",
    "            images = images*pink_noise\n",
    "            images = images/images.max()\n",
    "        \n",
    "        # Change the contrast | Изменить контрастность\n",
    "        images = random_power(images, power = 2, c= 0.7)\n",
    "        \n",
    "        # Expand to 3 channels | Расширить до 3 каналов\n",
    "        #images = torch.from_numpy(np.stack([images, images, images])).float()\n",
    "        images = mono_to_color(images,hp.len_chack[0])\n",
    "\n",
    "        # Draw pictures | Рисуем графики\n",
    "        if random.random()<0.0001:\n",
    "            img = images.numpy()\n",
    "            img = img - img.min()\n",
    "            img = img/img.max()\n",
    "            img = np.moveaxis(img, 0, 2)\n",
    "            imgplot = plt.imshow(img)\n",
    "            plt.savefig('log/img/'+(\"_\".join(self.hp.INV_BIRD_CODE[x] for x in birds))+'_'+sample.file+'.png')    \n",
    "        \n",
    "        # If there are no birds, then the background | Усли нет птиц, значит фон\n",
    "        if not birds:\n",
    "            birds.append(264)        \n",
    "        \n",
    "        # The background is 0.3, and the marked bird is 1 | Фон это 0.3, а помеченая птица 1\n",
    "        for bird in background:\n",
    "            if bird < len(y):\n",
    "                y[bird]=0.3\n",
    "        for bird in birds:\n",
    "            #if not bird==264:\n",
    "            y[bird]=1\n",
    "        return images, y\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--> Cette methode va nous permettre d'appliquer certains changements sur nos melspectogrammes . \n",
    "\n",
    "On va l'initialiser avec : \n",
    "1) bird_list : DataFrame des oiseaux\n",
    "2) hp : Notre classe Hparams\n",
    "3) noise : Notre Dataframe de bruit\n",
    "4) stop_border : la probabilité pour stopper le mélange \n",
    "5) level_noise : le seuil du bruit \n",
    "6) div_coef = la valeur avec lequel on va amplifier le mix \n",
    "\n",
    "\n",
    "---> La méthode __len__ va nous permettre de récuperer la taile de la liste de nos melspectogrammes . \n",
    "\n",
    "---> La méthode __getitem__ va nous permettre de rajouter du bruit , de modifier le contraste de l'image , de melanger des audios . \n",
    "    --> En entrée on a un fichier melspectogramme idx\n",
    "    --> On choisit aléatoirement deux fichiers melspectogramme idx2 et idx3 \n",
    "    --> On remplit un Tenseur rempli de zéros\n",
    "    --> On Crée deux listes birds et background\n",
    "    --> On crée une longueur len_chack pour le nouveau mel qu'on va créer \n",
    "    --> initialisation d'une variable images de dimension (la taille de mels , et la longueur len_chack)\n",
    "    --> On boucle sur les trois fichiers \n",
    "    --> On récupère toutes les colonnes de l'audio dans le Dataframe \n",
    "    --> On va charger le premier fichier melspectogramme dans un tenseur\n",
    "    --> On va spliter pour récupérer tous les oideaux dans le fichier et les ajouter dans la liste birds  \n",
    "    --> On va vérifier si il y a des oiseaux en arrière plan grace à la colonne \"labels_bg\" si c'est le cas on va spliter et       récupérer les codes de ces oiseaux pour les rajouter dans la liste background . \n",
    "    --> on vérifie si la taille du melspectogramme de l'audio esr supérieur à la taille qu'on a crée on va initialiser une          variable start avec une valeur aléatoire . \n",
    "    --> On va rétrecir le melspectogramme pour seulement récupérer la partie ou il y a l'audio \n",
    "    --> Dans le cas où le melspectogramme est plus court on va rambourer en rajoutant des zeros au mel \n",
    "    --> On va utiliser random_power pour changer le contraste\n",
    "    --> On va mixer la nouvelle l'image qu'on avait initialiser avec le melspectogramme pour avoir une nouvelle image \n",
    "    --> On va initialiser la variable idy avec une valeur aléatoire poour pourvoir le récupérer dans le Dataframe des audios de     bruit\n",
    "    --> On va effectuer le meme processus que dans la première partie sauf que là notre audio sera avec le bruit .\n",
    "    --> On va ensuite rajouter différents types de bruit le buit rose ( C'est un signal aléatoire dont la densité spectale est      constante) , et rajouter une passe-bande de bruit qui va attenuer certains sons désagréables . \n",
    "    --> On va diminuer les fréquences les plus basses de la nouvelles images , changer le contraste de l'image . \n",
    "    --> On va déssiner l'image et la sauvergedar dans le repertoire images .\n",
    "    --> On va regarder la présence d'oiseaux on rajoute le bruit dans le cas où il y aurait un oiseau en arrière on rajoute 0.3\n",
    "    pour la probabilité de l'oiseau et 1 si il est en premier plan . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,epochs,train_accuracy,all_loss,best_bird_count,best_score, t_scores, f1_scores, b_scores):\n",
    "    # Create a folder for logs | Создать папку для логов\n",
    "    save_dir = os.path.join(\"./log\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Upload a list of training files | Загрузить список тренировочных mel meta.csv\n",
    "    bird_list = pd.read_csv(\"meta.csv\")\n",
    "    bird_list = bird_list[bird_list.bird.isin(hp.bird_count)].reset_index(drop=True)\n",
    "    bird_list = bird_list.fillna(0)\n",
    "    train_count = len(bird_list)\n",
    "    trainset = MelDataset(bird_list, hp)\n",
    "    train_loader = data.DataLoader(trainset, batch_size = hp.batch_size, shuffle=True, drop_last=True, num_workers = 2)\n",
    "    \n",
    "    # Training process | Процесс обучения\n",
    "    prediction_dict = {}\n",
    "    start = time.time()\n",
    "    model.zero_grad() \n",
    "    for epoch in range(epochs, 1000):\n",
    "        step = 0\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        for (mel, background) in train_loader:\n",
    "            step+=1\n",
    "            # Consider the network output | Считаем выход сети\n",
    "            prediction = model(mel.cuda())\n",
    "            \n",
    "            # We consider an error | Считаем ошибку\n",
    "            train_loss = nn.BCEWithLogitsLoss()(prediction, background.cuda())\n",
    "            #train_loss = nn.CrossEntropyLoss()(prediction, np.argmax(background, axis = 1).cuda())\n",
    "            \n",
    "            # Calculate the gradients and make a step | Вычисляем градиенты и делаем шаг \n",
    "            train_loss.backward()\n",
    "            if not step % (100//hp.batch_size): \n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "            \n",
    "            # Saving error and accuracy | Сохраняем ошибку и точность\n",
    "            train_accuracy.append(accuracy(background, prediction))\n",
    "            all_loss.append(train_loss.detach().cpu().numpy())\n",
    "            \n",
    "            # Every hp.save_interval steps we display statistics | Каждые 100 шагов выводим статистику\n",
    "            if not step % hp.save_interval:\n",
    "                print(str(epoch)+' '+str(step)+'/'+str(train_count//hp.batch_size), \n",
    "                        \"время: %.3f loss: %.3f accuracy: %.3f \" % (\n",
    "                        (time.time()-start_time)/hp.save_interval,\n",
    "                        np.mean(all_loss[-hp.save_interval:])*10,\n",
    "                        np.mean(train_accuracy[-hp.save_interval:])))\n",
    "                # Test | Тестируем \n",
    "                (bird_count, bird_accuracy, test_accuracy), _ = generate([model],epochs,hp.border,True)\n",
    "                if bird_accuracy>0:\n",
    "                    t_scores.append(bird_accuracy)\n",
    "                    f1_scores.append(test_accuracy)\n",
    "                    b_scores.append(bird_count)\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                # Draw graphs | Рисуем графики\n",
    "                plt.clf()\n",
    "                plt.plot(gaussian_filter1d(train_accuracy[80:], 20))\n",
    "                plt.plot(gaussian_filter1d(all_loss[80:], 20)*10)\n",
    "                plt.savefig('log/all_loss.png')        \n",
    "                plt.clf()\n",
    "                plt.plot(t_scores)\n",
    "                plt.savefig('log/t.png') \n",
    "                plt.clf()\n",
    "                plt.plot(f1_scores)\n",
    "                plt.savefig('log/f1.png')\n",
    "                plt.clf()\n",
    "                plt.plot(b_scores)\n",
    "                plt.savefig('log/b.png')\n",
    "                # Saving the model | Сохраняем модель\n",
    "                if (bird_count>best_bird_count or test_accuracy>best_score or step==hp.save_interval):\n",
    "                    if bird_count>best_bird_count:\n",
    "                        best_bird_count = bird_count\n",
    "                    if test_accuracy>best_score:\n",
    "                        best_score = test_accuracy\n",
    "                    \n",
    "                    torch.save({\n",
    "                        'model': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'epoch': epoch,\n",
    "                        'best_bird_count': bird_count,\n",
    "                        'best_score': test_accuracy,\n",
    "                        'train_accuracy': train_accuracy,\n",
    "                        'all_loss': all_loss,\n",
    "                        't_scores': t_scores,\n",
    "                        'f1_scores': f1_scores,\n",
    "                        'b_scores': b_scores,                        \n",
    "                    }, 'log/enet_%d_%.3f_%.3f.pt' % (bird_count,bird_accuracy,test_accuracy))\n",
    "                    print(\"Модель сохранена\")\n",
    "                start_time = time.time()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "La méthode train va nous permettre d'entrainer notre model : \n",
    "\n",
    "1) Dans un premier temps on va créer un dossier qui contiendra nos erreurs\n",
    "2) On Charge le fichier csv \"meta.csv\" dans bird_list \n",
    "3) On récupère garde les lignes qui sont contenues dans la list bird_count \n",
    "4) on remplace les données manquantes par des 0 \n",
    "5) On recupère la longueur de la liste des oiseaux \n",
    "6) on va appliquer notre méthode MelDatset avec deux paramètres qui sont notre dataframe d'oiseaux et le paramètre hp qui contient les paramètres dont on a besoin , et on va le rattacher à notre variable trainset \n",
    "7) On va Charger nos données d'entrainement avec DataLoader pour pouvoir entrainer notre réseau .\n",
    "8) on crée un dictionnaire pour récupérer les prédictions \n",
    "9) On appelle time() pour pouvoir voir le temps d'éxécution \n",
    "10) on remet à zéro les paramètres du model\n",
    "11) On va effectuer (1000 - Epochs) epoch pour entrainer notre model\n",
    "12) on initialise la variable step à 0 \n",
    "13) on lance l'entrainement du model \n",
    "14) On va boucler sur nos mel et la liste de audios avec les oiseaux en arrière plan \n",
    "15) on predit la sortie à partir du mel \n",
    "16) on calcule les erreurs  \n",
    "17) On applique le gradient pour réduire l'erreur et on sauvegarde l'erreur et l'accuracy et on n'oublie pas de remettre les valeurs à zero pour ne pas que ça s'additionne \n",
    "18) On affiche les stastiques \n",
    "19) On entraine encore le model\n",
    "20) On dessine nos graphiques \n",
    "21) On regarde si on a obtient une meilleure accuracy , un meilleur nombre d'oiseaux ou que le nombre de pas est égal à hp.interval on regarde les valeurs pour le bird_count_best et test_accuracy et on sauvegarde notre model \n",
    ". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(models, epochs, border,log_stat):\n",
    "    start = time.time() \n",
    "    preds = []\n",
    "\n",
    "    # Uploading a list of files for testing | Загружаем список файлов для тестирования\n",
    "    TEST_FOLDER = f'{BASE_TEST_DIR}/test_audio/'\n",
    "    test_info = pd.read_csv(f'{BASE_TEST_DIR}/test.csv')\n",
    "    \n",
    "    # Looking for all unique audio recordings | Ищем все уникальные аудиозаписи\n",
    "    unique_audio_id = test_info.audio_id.unique() \n",
    "    \n",
    "    # Predict | Предсказываем\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    with torch.no_grad():    \n",
    "        for audio_id in unique_audio_id:\n",
    "            # Getting a spectrogram | Получаем спектрограмму\n",
    "            melspectr = get_melspectr(TEST_FOLDER + audio_id + \".mp3\")\n",
    "            melspectr = librosa.power_to_db(melspectr, amin=1e-7, ref=np.max)\n",
    "            melspectr = ((melspectr+80)/80).astype(np.float16)\n",
    "            \n",
    "            # Looking for all the excerpts for this sound | Ищем все отрывки для данного звука  \n",
    "            test_df_for_audio_id = test_info.query(f\"audio_id == '{audio_id}'\").reset_index(drop=True)\n",
    "            est_bird =np.zeros((265))\n",
    "            probass = {}\n",
    "            \n",
    "            # Проходим по все отрывкам \n",
    "            for index, row in test_df_for_audio_id.iterrows():\n",
    "                # Getting the site, start time, and id | Получаем сайт, время начала и id\n",
    "                site = row['site']\n",
    "                start_time = row['seconds'] - 5\n",
    "                row_id = row['row_id']\n",
    "                mels = []\n",
    "                probas = None\n",
    "                \n",
    "                # Cut out the desired piece | Вырезаем нужный кусок\n",
    "                if site == 'site_1' or site == 'site_2':\n",
    "                    start_index = int(hp.sr * start_time/hp.hop_length)\n",
    "                    end_index = int(hp.sr * row['seconds']/hp.hop_length)                \n",
    "                    y = melspectr[:,start_index:end_index]\n",
    "                else:\n",
    "                    y = melspectr\n",
    "                    \n",
    "                # cutting off the tail | отсекаю хвост\n",
    "                if (y.shape[1]%hp.len_chack[0]):\n",
    "                    y = y[:,:-(y.shape[1]%448)]\n",
    "                \n",
    "                prob = []\n",
    "                for i,model in enumerate(models):\n",
    "                    mels = []\n",
    "                    probas = None                    \n",
    "                    # Split into several chunks with the duration hp.len_chack | Разбиваем на несколько кусков длительностью hp.len_chack\n",
    "                    ys = np.reshape(y, (hp.n_mels, -1, hp.len_chack[i]))\n",
    "                    ys = np.moveaxis(ys, 1, 0)\n",
    "\n",
    "                    # For each piece we make transformations | Для каждого куска делаем преобразования\n",
    "                    for image in ys:\n",
    "                        # Convert to 3 colors and normalize | Переводим в 3 цвета и нормализуем\n",
    "                        image = image/image.max()\n",
    "                        #image = image**0.85\n",
    "                        #image = torch.from_numpy(np.stack([image, image, image])).float()\n",
    "                        image = mono_to_color(image,hp.len_chack[i])\n",
    "                        mels.append(image)\n",
    "\n",
    "                    mels = np.stack(mels)                \n",
    "                    \n",
    "                    # Прохожу по всем batch\n",
    "                    for n in range(0,len(mels),hp.batch_size):\n",
    "                        if len(mels) == 1:\n",
    "                            mel = np.array(mels)\n",
    "                        else:\n",
    "                            mel = mels[n:n+hp.batch_size]\n",
    "\n",
    "                        mel = torch.from_numpy(mel).cuda()\n",
    "\n",
    "                        # Predict | Получить выход модели\n",
    "                        prediction = model(mel)\n",
    "                        #prediction = F.softmax(prediction, dim=1)\n",
    "                        prediction = torch.sigmoid(prediction)\n",
    "\n",
    "                        # in numpy\n",
    "                        proba = prediction.detach().cpu().numpy()\n",
    "\n",
    "                        # Add zeros up to 265 | Добавить нули до 265\n",
    "                        proba = np.concatenate((proba,np.zeros((proba.shape[0],265-proba.shape[1]))), axis=1)\n",
    "\n",
    "                        # Adding to the array | Добавляю в массив\n",
    "                        if not probas is None:\n",
    "                            probas = np.append(probas, proba, axis = 0)\n",
    "                        else:\n",
    "                            probas = proba\n",
    "                        if hp.len_chack[i] == 448:\n",
    "                            probas = np.append(probas, proba, axis = 0)\n",
    "                    prob.append(probas)\n",
    "\n",
    "                # Averaging the ensemble | Усредняю ансамбль\n",
    "                prob = np.stack(prob,axis=0)\n",
    "                prob = prob**2\n",
    "                proba = prob.mean(axis=0)#gmean(prob)/2 + prob.mean(axis=0)/2\n",
    "                proba = proba**(1/2)\n",
    "                \n",
    "                # If a bird is encountered in one segment, increase its probability in others\n",
    "                # Если встретилась птица в одном отрезке, увеличить её вероятность в других\n",
    "                for xx in proba:\n",
    "                    z = xx.copy()\n",
    "                    z[z<0.5] = 0\n",
    "                    est_bird = est_bird + z/70\n",
    "                    est_bird[(est_bird<0.15)&(est_bird>0)] = 0.15\n",
    "      \n",
    "                # Dictionary with an array of all passages | Словарь с массивом всех отрывков\n",
    "                probass[row_id] = proba\n",
    "            \n",
    "            est_bird[est_bird>0.3] = 0.3\n",
    "            for row_id,probas in probass.items():\n",
    "                prediction_dict = []\n",
    "                for proba in probas:\n",
    "                    proba += est_bird\n",
    "                    events = proba > border\n",
    "                    labels = np.argwhere(events).reshape(-1).tolist()\n",
    "\n",
    "                    # To convert in the name of the bird | Преобразовать в название птиц\n",
    "                    if len(labels) == 0  or (264 in labels):\n",
    "                        continue\n",
    "                    else:\n",
    "                        labels_str_list = list(map(lambda x: hp.INV_BIRD_CODE[x], labels))\n",
    "                        for i in labels_str_list:\n",
    "                            if i not in prediction_dict:\n",
    "                                prediction_dict.append(i)  \n",
    "                    \n",
    "                # If birds are not predicted | Если не предсказываются птицы\n",
    "                if len(prediction_dict) == 0:\n",
    "                    prediction_dict = \"nocall\"\n",
    "                else:\n",
    "                    prediction_dict = \" \".join(prediction_dict)\n",
    "          \n",
    "                # To add to the list | Добавить в список\n",
    "                preds.append([row_id, prediction_dict])\n",
    "\n",
    "        # Convert to DataFrame and save | Перевести в DataFrame и сохранить\n",
    "        preds = pd.DataFrame(preds, columns=['row_id', 'birds'])\n",
    "        preds.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    return test_accuracy(preds,log_stat,border), time.time() - start\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cette méthode va nous permettre de tester nos models sur nos jeux de données \n",
    "\n",
    "1) On récupère le dossier des fichiers \n",
    "2) On charge le Dataframe concernant les audios de test \n",
    "3) on récupère les identifiants unique des audios\n",
    "4) On va boucler sur tous les models en spécifiant à torch qu'on est en mode eval en utilisant no_grrad on réduire l'utilisation de la memoire et accéléra le temps d'exécution \n",
    "5) On va transformer nos audios en melspectogramme \n",
    "6) On va contraster notre image \n",
    "7) On va rechercher tous les extraits de cette audio \n",
    "8) On va parcourir tous les passages en récuperant \n",
    "9) On va découper la partie souhaitée \n",
    "10) On coupe la fin seulement si la taille est supérieur à la longueur qu'on a choisi\n",
    "11) On parcourt tous les models et on va dans un premier temps séparer en plusieurs morceaux avec la durée qu'on aura choisi . \n",
    "12) Pour tous les morceaux on effectue les transformations\n",
    "13) On effectue nos prédiction avec le model \n",
    "14) On utilise la fonction softmax pour aoir une proba \n",
    "15) On rajoute toutes les probas et on fait la moyenne après \n",
    "16) Si un oiseau est trouvé on augmente a probabilité \n",
    "17) On crée un dictionnaire avec tous les probas de tous les dictionnaires . \n",
    "18) On finit par retourner la fonction test_accuracy et le temps qu'on a mis pour l'exécution de cette méthode .  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
